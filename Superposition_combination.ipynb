{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c27e354-1ced-4f44-b286-5375eda1184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from experiment.run import multiple_run\n",
    "from utils.utils import boolean_string\n",
    "import logging\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "from continuum.continuum import continuum\n",
    "from continuum.data_utils import setup_test_loader\n",
    "from utils.name_match import agents\n",
    "from utils.setup_elements import setup_opt, setup_architecture\n",
    "from utils.utils import maybe_cuda, AverageMeter\n",
    "from experiment.metrics import compute_performance, single_run_avg_end_fgt\n",
    "from experiment.tune_hyperparam import tune_hyper\n",
    "from types import SimpleNamespace\n",
    "from utils.io import load_yaml, save_dataframe_csv, check_ram_usage\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from utils.utils import maybe_cuda\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from utils.buffer.buffer_utils import random_retrieve, get_grad_vector\n",
    "import copy\n",
    "from utils.buffer.buffer import Buffer, Second_Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdb8698-82e3-476b-909c-8ef139959730",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'num_runs': 1,\n",
    "    'seed': 0,\n",
    "    'val_size': 0.1,\n",
    "    'num_val': 3,\n",
    "    'num_runs_val': 3,\n",
    "    'error_analysis': False,  \n",
    "    'verbose': True,  \n",
    "    'store': False,  \n",
    "    'save_path': './',\n",
    "    'imagenet_path': './imagenet1k',\n",
    "    'agent': 'SUPER',\n",
    "    'update': 'random',\n",
    "    'retrieve': 'random',\n",
    "    'second_buffer': False,  \n",
    "    'update2': 'random',\n",
    "    'retrieve2': 'random',\n",
    "    # 'ratio': 0.2,  \n",
    "    'optimizer': 'SGD',\n",
    "    'learning_rate': 0.1,\n",
    "    'epoch': 1,\n",
    "    'batch': 10,\n",
    "    'test_batch': 10000,\n",
    "    'weight_decay': 0,\n",
    "    'num_tasks': 20,\n",
    "    'fix_order': False,  \n",
    "    'plot_sample': False, \n",
    "    'data': \"cifar100\",\n",
    "    'cl_type': \"nc\",\n",
    "    'ns_factor': (0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6),\n",
    "    'ns_type': 'noise',\n",
    "    'ns_task': (1, 1, 2, 2, 2, 2),\n",
    "    'online': True, \n",
    "    'use_momentum': True,  \n",
    "    'mem_size': 10000,\n",
    "    'eps_mem_batch': 5,\n",
    "    'sub_eps_mem_batch': 5,\n",
    "    'lambda_': 100,\n",
    "    'alpha': 0.9,\n",
    "    'fisher_update_after': 50,\n",
    "    'subsample': 50,\n",
    "    'gss_mem_strength': 10,\n",
    "    'gss_batch_size': 10,\n",
    "    'k': 5,\n",
    "    'aser_type': \"asvm\",\n",
    "    'n_smp_cls': 2.0,\n",
    "    'stm_capacity': 1000,\n",
    "    'classifier_chill': 0.01,\n",
    "    'log_alpha': -300,\n",
    "    'minlr': 0.0005,\n",
    "    'clip': 10.,\n",
    "    'mem_epoch': 70,\n",
    "    'labels_trick': False,  \n",
    "    'separated_softmax': False,  \n",
    "    'kd_trick': False, \n",
    "    'kd_trick_star': False,  \n",
    "    'review_trick': False,  \n",
    "    'ncm_trick': False,  \n",
    "    'mem_iters': 1,\n",
    "    'min_delta': 0.,\n",
    "    'patience': 0,\n",
    "    'cumulative_delta': False,  \n",
    "    'temp': 0.07,\n",
    "    'buffer_tracker': False,  \n",
    "    'warmup': 4,\n",
    "    'head': 'mlp',\n",
    "    'exp': 'PCR',\n",
    "    'Triplet': False, \n",
    "    'top5': False,  \n",
    "    'mem_bank_size': 1,\n",
    "    'num_subcentroids': 4,\n",
    "    'PSC': False,  \n",
    "    'onlyPSC': False,  \n",
    "    'gamma': 0.999,\n",
    "    'buffer_lip_lambda': 0.5,\n",
    "    'budget_lip_lambda': 0.5,\n",
    "    'headless_init_act': \"relu\",\n",
    "    'grad_iter_step': -2,\n",
    "    'lr': 0.0001,\n",
    "    'optim_wd': 0.,\n",
    "    'optim_mom': 0.,\n",
    "    'optim_nesterov': 0,\n",
    "    'ignore_other_metrics': 0,\n",
    "    'debug_mode': 0,\n",
    "    'reg_weight': 0.1,\n",
    "    'stable_model_update_freq': 0.70,\n",
    "    'stable_model_alpha': 0.999,\n",
    "    'plastic_model_alpha': 0.999,\n",
    "    'ucr_max': True,  \n",
    "    'save_cp': False,  \n",
    "    # 'cp_name': 'checkpoint.pth',\n",
    "    'cp_path': './checkpoint',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94ad54-4e8a-4a93-be7e-32fe658d8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7513d84-3850-4479-a518-2e2a7b7f08ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task: 0, Labels:[26, 86, 2, 55, 75]\n",
      "Task: 1, Labels:[93, 16, 73, 54, 95]\n",
      "Task: 2, Labels:[53, 92, 78, 13, 7]\n",
      "Task: 3, Labels:[30, 22, 24, 33, 8]\n",
      "Task: 4, Labels:[43, 62, 3, 71, 45]\n",
      "Task: 5, Labels:[48, 6, 99, 82, 76]\n",
      "Task: 6, Labels:[60, 80, 90, 68, 51]\n",
      "Task: 7, Labels:[27, 18, 56, 63, 74]\n",
      "Task: 8, Labels:[1, 61, 42, 41, 4]\n",
      "Task: 9, Labels:[15, 17, 40, 38, 5]\n",
      "Task: 10, Labels:[91, 59, 0, 34, 28]\n",
      "Task: 11, Labels:[50, 11, 35, 23, 52]\n",
      "Task: 12, Labels:[10, 31, 66, 57, 79]\n",
      "Task: 13, Labels:[85, 32, 84, 14, 89]\n",
      "Task: 14, Labels:[19, 29, 49, 97, 98]\n",
      "Task: 15, Labels:[69, 20, 94, 72, 77]\n",
      "Task: 16, Labels:[25, 37, 81, 46, 39]\n",
      "Task: 17, Labels:[65, 58, 12, 88, 70]\n",
      "Task: 18, Labels:[87, 36, 21, 83, 9]\n",
      "Task: 19, Labels:[96, 67, 64, 47, 44]\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(**parameters)\n",
    "params = args\n",
    "params.cuda = torch.cuda.is_available()\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if params.cuda:\n",
    "    torch.cuda.manual_seed(params.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "params.trick = {'labels_trick': args.labels_trick, 'separated_softmax': args.separated_softmax,\n",
    "                  'kd_trick': args.kd_trick, 'kd_trick_star': args.kd_trick_star, 'review_trick': args.review_trick,\n",
    "                  'ncm_trick': args.ncm_trick}\n",
    "data_continuum = continuum(params.data, params.cl_type, params)\n",
    "\n",
    "data_continuum.new_run()\n",
    "test_loaders = setup_test_loader(data_continuum.test_data(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff359c84-4dfa-4de4-a68c-8a60c450a2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = setup_architecture(params)\n",
    "model = maybe_cuda(model, params.cuda)\n",
    "checkpoint1_path = f'./checkpoint/Superposition_batch500_task20_epoch50_checkpoint_run0_batch19_epoch49.pth'\n",
    "checkpoint = torch.load(checkpoint1_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8aa5550-22ab-4835-94f1-64fdd55f3c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.336 0.442 0.47  0.634 0.54  0.704 0.72  0.586 0.712 0.756 0.778 0.698\n",
      " 0.716 0.782 0.746 0.844 0.774 0.848 0.882 0.748]\n"
     ]
    }
   ],
   "source": [
    "# Check model accuracy\n",
    "\n",
    "model.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            logits, _, _ = model(batch_x, task)\n",
    "            _, pred_label = torch.max(logits, 1)\n",
    "            correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "            acc.update(correct_cnt, batch_y.size(0))\n",
    "            # print(correct_cnt)\n",
    "        acc_array[task] = acc.avg()\n",
    "    print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf01684-4502-45c8-a2d8-7d19b27556cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.336 0.442 0.47  0.634 0.54  0.704 0.72  0.586 0.712 0.756 0.778 0.698\n",
      " 0.716 0.782 0.746 0.844 0.774 0.848 0.882 0.748]\n"
     ]
    }
   ],
   "source": [
    "#Load customized model\n",
    "from models.resnet_hash_t import HashResNet18\n",
    "# batch_x.shape\n",
    "model2 = HashResNet18(100)\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model2 = maybe_cuda(model2, params.cuda)\n",
    "# z = torch.randn(20, requires_grad=True, device='cuda')\n",
    "# z = torch.randn(20, device='cuda')\n",
    "z = torch.zeros(20, device='cuda')\n",
    "# output, _, _ = model2(batch_x, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22284f1a-5d98-425a-96a3-44153ea01903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2761))  # CIFAR-100 的标准化值\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./datasets', train=True, download=True, transform=transform)\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(train_dataset):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "target_fraction = 1\n",
    "num_classes = 100\n",
    "per_class_samples = int(len(train_dataset) * target_fraction // num_classes)\n",
    "\n",
    "selected_indices = []\n",
    "for label, indices in class_indices.items():\n",
    "    selected_indices.extend(np.random.choice(indices, per_class_samples, replace=False))\n",
    "\n",
    "subset_dataset = Subset(train_dataset, selected_indices)\n",
    "\n",
    "batch_size = 1000\n",
    "sub_train_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5efa56a2-b619-49be-9968-ea0be7399283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:40<00:00, 20.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "z_o = torch.randn(20, requires_grad=True, device='cuda')\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = torch.optim.SGD([z], lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "for _ in tqdm(range(5)):\n",
    "    for x, y in sub_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = maybe_cuda(x, \"cuda\")\n",
    "        y = maybe_cuda(y, \"cuda\")\n",
    "        output, _, _ = model2(x, z_o)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bcbf7fe-f5b5-4543-be8e-7460c4ba2165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 3, 32, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3a223f8-1ee5-4ec3-9ffb-d4b54e19cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5378,  0.5006, -0.2525, -0.4607, -1.6402, -1.2988,  0.3318, -1.5888,\n",
      "         1.0011,  1.4593,  0.7027,  0.1478,  1.1435,  0.5339, -0.0725,  0.5111,\n",
      "         0.0616,  0.4664,  0.4524, -1.0453], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(z_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ed48bd0-f1b2-44d3-a85c-e891d230a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.002 0.    0.    0.    0.    0.186 0.   ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model2.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            logits, _, _ = model2(batch_x, z_o)\n",
    "            _, pred_label = torch.max(logits, 1)\n",
    "            correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "            acc.update(correct_cnt, batch_y.size(0))\n",
    "            # print(correct_cnt)\n",
    "        acc_array[task] = acc.avg()\n",
    "    print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b21334a-715d-4270-880e-3afe08c9a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.336 0.442 0.47  0.634 0.54  0.704 0.72  0.586 0.712 0.756 0.778 0.698\n",
      " 0.716 0.782 0.746 0.844 0.774 0.848 0.882 0.748]\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            z0 = torch.zeros(20, device='cuda')\n",
    "            z0[task] = 1\n",
    "            logits, _, _ = model2(batch_x, z0)\n",
    "            _, pred_label = torch.max(logits, 1)\n",
    "            correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "            acc.update(correct_cnt, batch_y.size(0))\n",
    "            # print(correct_cnt)\n",
    "        acc_array[task] = acc.avg()\n",
    "    print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b16ffb-7e4c-4cdc-87cd-2ec5edf983c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
