{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c27e354-1ced-4f44-b286-5375eda1184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from experiment.run import multiple_run\n",
    "from utils.utils import boolean_string\n",
    "import logging\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "import time\n",
    "from continuum.continuum import continuum\n",
    "from continuum.data_utils import setup_test_loader\n",
    "from utils.name_match import agents\n",
    "from utils.setup_elements import setup_opt, setup_architecture\n",
    "from utils.utils import maybe_cuda, AverageMeter\n",
    "from experiment.metrics import compute_performance, single_run_avg_end_fgt\n",
    "from experiment.tune_hyperparam import tune_hyper\n",
    "from types import SimpleNamespace\n",
    "from utils.io import load_yaml, save_dataframe_csv, check_ram_usage\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from utils.utils import maybe_cuda\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from utils.buffer.buffer_utils import random_retrieve, get_grad_vector\n",
    "import copy\n",
    "from utils.buffer.buffer import Buffer, Second_Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdb8698-82e3-476b-909c-8ef139959730",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'num_runs': 1,\n",
    "    'seed': 0,\n",
    "    'val_size': 0.1,\n",
    "    'num_val': 3,\n",
    "    'num_runs_val': 3,\n",
    "    'error_analysis': False,  \n",
    "    'verbose': True,  \n",
    "    'store': False,  \n",
    "    'save_path': './',\n",
    "    'imagenet_path': './imagenet1k',\n",
    "    'agent': 'SUPER',\n",
    "    'update': 'random',\n",
    "    'retrieve': 'random',\n",
    "    'second_buffer': False,  \n",
    "    'update2': 'random',\n",
    "    'retrieve2': 'random',\n",
    "    # 'ratio': 0.2,  \n",
    "    'optimizer': 'SGD',\n",
    "    'learning_rate': 0.1,\n",
    "    'epoch': 1,\n",
    "    'batch': 10,\n",
    "    'test_batch': 10000,\n",
    "    'weight_decay': 0,\n",
    "    'num_tasks': 20,\n",
    "    'fix_order': False,  \n",
    "    'plot_sample': False, \n",
    "    'data': \"cifar100\",\n",
    "    'cl_type': \"nc\",\n",
    "    'ns_factor': (0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6),\n",
    "    'ns_type': 'noise',\n",
    "    'ns_task': (1, 1, 2, 2, 2, 2),\n",
    "    'online': True, \n",
    "    'use_momentum': True,  \n",
    "    'mem_size': 10000,\n",
    "    'eps_mem_batch': 5,\n",
    "    'sub_eps_mem_batch': 5,\n",
    "    'lambda_': 100,\n",
    "    'alpha': 0.9,\n",
    "    'fisher_update_after': 50,\n",
    "    'subsample': 50,\n",
    "    'gss_mem_strength': 10,\n",
    "    'gss_batch_size': 10,\n",
    "    'k': 5,\n",
    "    'aser_type': \"asvm\",\n",
    "    'n_smp_cls': 2.0,\n",
    "    'stm_capacity': 1000,\n",
    "    'classifier_chill': 0.01,\n",
    "    'log_alpha': -300,\n",
    "    'minlr': 0.0005,\n",
    "    'clip': 10.,\n",
    "    'mem_epoch': 70,\n",
    "    'labels_trick': False,  \n",
    "    'separated_softmax': False,  \n",
    "    'kd_trick': False, \n",
    "    'kd_trick_star': False,  \n",
    "    'review_trick': False,  \n",
    "    'ncm_trick': False,  \n",
    "    'mem_iters': 1,\n",
    "    'min_delta': 0.,\n",
    "    'patience': 0,\n",
    "    'cumulative_delta': False,  \n",
    "    'temp': 0.07,\n",
    "    'buffer_tracker': False,  \n",
    "    'warmup': 4,\n",
    "    'head': 'mlp',\n",
    "    'exp': 'PCR',\n",
    "    'Triplet': False, \n",
    "    'top5': False,  \n",
    "    'mem_bank_size': 1,\n",
    "    'num_subcentroids': 4,\n",
    "    'PSC': False,  \n",
    "    'onlyPSC': False,  \n",
    "    'gamma': 0.999,\n",
    "    'buffer_lip_lambda': 0.5,\n",
    "    'budget_lip_lambda': 0.5,\n",
    "    'headless_init_act': \"relu\",\n",
    "    'grad_iter_step': -2,\n",
    "    'lr': 0.0001,\n",
    "    'optim_wd': 0.,\n",
    "    'optim_mom': 0.,\n",
    "    'optim_nesterov': 0,\n",
    "    'ignore_other_metrics': 0,\n",
    "    'debug_mode': 0,\n",
    "    'reg_weight': 0.1,\n",
    "    'stable_model_update_freq': 0.70,\n",
    "    'stable_model_alpha': 0.999,\n",
    "    'plastic_model_alpha': 0.999,\n",
    "    'ucr_max': True,  \n",
    "    'save_cp': False,  \n",
    "    # 'cp_name': 'checkpoint.pth',\n",
    "    'cp_path': './checkpoint',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94ad54-4e8a-4a93-be7e-32fe658d8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7513d84-3850-4479-a518-2e2a7b7f08ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Task: 0, Labels:[26, 86, 2, 55, 75]\n",
      "Task: 1, Labels:[93, 16, 73, 54, 95]\n",
      "Task: 2, Labels:[53, 92, 78, 13, 7]\n",
      "Task: 3, Labels:[30, 22, 24, 33, 8]\n",
      "Task: 4, Labels:[43, 62, 3, 71, 45]\n",
      "Task: 5, Labels:[48, 6, 99, 82, 76]\n",
      "Task: 6, Labels:[60, 80, 90, 68, 51]\n",
      "Task: 7, Labels:[27, 18, 56, 63, 74]\n",
      "Task: 8, Labels:[1, 61, 42, 41, 4]\n",
      "Task: 9, Labels:[15, 17, 40, 38, 5]\n",
      "Task: 10, Labels:[91, 59, 0, 34, 28]\n",
      "Task: 11, Labels:[50, 11, 35, 23, 52]\n",
      "Task: 12, Labels:[10, 31, 66, 57, 79]\n",
      "Task: 13, Labels:[85, 32, 84, 14, 89]\n",
      "Task: 14, Labels:[19, 29, 49, 97, 98]\n",
      "Task: 15, Labels:[69, 20, 94, 72, 77]\n",
      "Task: 16, Labels:[25, 37, 81, 46, 39]\n",
      "Task: 17, Labels:[65, 58, 12, 88, 70]\n",
      "Task: 18, Labels:[87, 36, 21, 83, 9]\n",
      "Task: 19, Labels:[96, 67, 64, 47, 44]\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(**parameters)\n",
    "params = args\n",
    "params.cuda = torch.cuda.is_available()\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if params.cuda:\n",
    "    torch.cuda.manual_seed(params.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "params.trick = {'labels_trick': args.labels_trick, 'separated_softmax': args.separated_softmax,\n",
    "                  'kd_trick': args.kd_trick, 'kd_trick_star': args.kd_trick_star, 'review_trick': args.review_trick,\n",
    "                  'ncm_trick': args.ncm_trick}\n",
    "data_continuum = continuum(params.data, params.cl_type, params)\n",
    "\n",
    "data_continuum.new_run()\n",
    "test_loaders = setup_test_loader(data_continuum.test_data(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff359c84-4dfa-4de4-a68c-8a60c450a2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = setup_architecture(params)\n",
    "model = maybe_cuda(model, params.cuda)\n",
    "checkpoint1_path = f'./checkpoint/Superposition_batch500_task20_epoch50_checkpoint_run0_batch19_epoch49.pth'\n",
    "checkpoint = torch.load(checkpoint1_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8aa5550-22ab-4835-94f1-64fdd55f3c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context matrix number:  0\n",
      "[0.336 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.05 ]\n",
      "context matrix number:  1\n",
      "[0.    0.442 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.006]\n",
      "context matrix number:  2\n",
      "[0.    0.    0.47  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.052]\n",
      "context matrix number:  3\n",
      "[0.    0.    0.    0.634 0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.072]\n",
      "context matrix number:  4\n",
      "[0.    0.    0.    0.    0.54  0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.054]\n",
      "context matrix number:  5\n",
      "[0.    0.    0.    0.    0.    0.704 0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.002]\n",
      "context matrix number:  6\n",
      "[0.   0.   0.   0.   0.   0.   0.72 0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.  ]\n",
      "context matrix number:  7\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.586 0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  8\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.712 0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  9\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.756 0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  10\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.778 0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  11\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.698\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  12\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.716 0.    0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  13\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.782 0.    0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  14\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.746 0.    0.    0.    0.    0.   ]\n",
      "context matrix number:  15\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.844 0.    0.    0.    0.   ]\n",
      "context matrix number:  16\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.774 0.    0.    0.   ]\n",
      "context matrix number:  17\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.848 0.    0.   ]\n",
      "context matrix number:  18\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.882 0.   ]\n",
      "context matrix number:  19\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.748]\n"
     ]
    }
   ],
   "source": [
    "# Check model accuracy\n",
    "\n",
    "model.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "for context_matrix in range(20):\n",
    "    print(\"context matrix number: \", context_matrix)\n",
    "    with torch.no_grad():\n",
    "        for task, test_loader in enumerate(test_loaders):\n",
    "            # print(\"here\")\n",
    "            acc = AverageMeter()\n",
    "            for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "                batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "                batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "                logits, _, _ = model(batch_x, context_matrix)\n",
    "                _, pred_label = torch.max(logits, 1)\n",
    "                correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "                acc.update(correct_cnt, batch_y.size(0))\n",
    "                # print(correct_cnt)\n",
    "            acc_array[task] = acc.avg()\n",
    "        print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8832236d-b1e7-41c3-8524-f1efe1a41302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n",
      "0\n",
      "torch.Size([500, 100])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            print(i)\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            logits, _, _ = model(batch_x, context_matrix)\n",
    "            print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf01684-4502-45c8-a2d8-7d19b27556cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load customized model\n",
    "from models.resnet_hash_t import HashResNet18\n",
    "# batch_x.shape\n",
    "model2 = HashResNet18(100)\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model2 = maybe_cuda(model2, params.cuda)\n",
    "# z = torch.randn(20, requires_grad=True, device='cuda')\n",
    "# z = torch.randn(20, device='cuda')\n",
    "z = torch.zeros(20, device='cuda')\n",
    "# output, _, _ = model2(batch_x, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22284f1a-5d98-425a-96a3-44153ea01903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2761))  # CIFAR-100 的标准化值\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./datasets', train=True, download=True, transform=transform)\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(train_dataset):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "target_fraction = 1\n",
    "num_classes = 100\n",
    "per_class_samples = int(len(train_dataset) * target_fraction // num_classes)\n",
    "\n",
    "selected_indices = []\n",
    "for label, indices in class_indices.items():\n",
    "    selected_indices.extend(np.random.choice(indices, per_class_samples, replace=False))\n",
    "\n",
    "subset_dataset = Subset(train_dataset, selected_indices)\n",
    "\n",
    "batch_size = 1000\n",
    "sub_train_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efa56a2-b619-49be-9968-ea0be7399283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m sub_train_loader:\n\u001b[0;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m         x \u001b[38;5;241m=\u001b[39m maybe_cuda(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\PCR\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "z_o = torch.randn(20, requires_grad=True, device='cuda')\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = torch.optim.SGD([z], lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "for _ in tqdm(range(5)):\n",
    "    for x, y in sub_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x = maybe_cuda(x, \"cuda\")\n",
    "        y = maybe_cuda(y, \"cuda\")\n",
    "        output, _, _ = model2(x, z_o)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbf7fe-f5b5-4543-be8e-7460c4ba2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a223f8-1ee5-4ec3-9ffb-d4b54e19cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed48bd0-f1b2-44d3-a85c-e891d230a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            logits, _, _ = model2(batch_x, z_o)\n",
    "            _, pred_label = torch.max(logits, 1)\n",
    "            correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "            acc.update(correct_cnt, batch_y.size(0))\n",
    "            # print(correct_cnt)\n",
    "        acc_array[task] = acc.avg()\n",
    "    print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b21334a-715d-4270-880e-3afe08c9a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.338 0.442 0.47  0.634 0.54  0.704 0.72  0.586 0.712 0.756 0.778 0.698\n",
      " 0.716 0.782 0.746 0.844 0.774 0.848 0.882 0.748]\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "acc_array = np.zeros(len(test_loaders))\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        # print(\"here\")\n",
    "        acc = AverageMeter()\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "            z0 = torch.zeros(20, device='cuda')\n",
    "            z0[task] = 1\n",
    "            logits, _, _ = model2(batch_x, z0)\n",
    "            _, pred_label = torch.max(logits, 1)\n",
    "            correct_cnt = (pred_label == batch_y).sum().item() / batch_y.size(0)\n",
    "            acc.update(correct_cnt, batch_y.size(0))\n",
    "            # print(correct_cnt)\n",
    "        acc_array[task] = acc.avg()\n",
    "    print(acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b16ffb-7e4c-4cdc-87cd-2ec5edf983c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "059af50e-c90a-4812-9240-31bf2fff9e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   1.,   2.,  16.,\n",
      "           4.,   7.,  10.,  25.,  22.,  22., 118., 271.],\n",
      "        [  0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   5.,   2.,   7.,  25.,\n",
      "           3.,   3.,   8.,  41.,  12.,  51.,  92., 250.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   6.,   0.,   5.,  11.,\n",
      "           5.,   5.,   8.,   6.,  29.,  81., 126., 217.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   4.,   2.,   4.,  16.,\n",
      "           3.,   7.,  16.,  19.,  14.,  39.,  90., 285.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   8.,   0.,   2.,   0.,   4.,  10.,\n",
      "           4.,   9.,  13.,  13.,  15.,  80., 146., 196.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   3.,   0.,   6.,   5.,\n",
      "           3.,   7.,  13.,  16.,  15.,  45., 120., 266.],\n",
      "        [  0.,   0.,   0.,   0.,   1.,   1.,  27.,   0.,   1.,   1.,   1.,   7.,\n",
      "           1.,   5.,  11.,  13.,  20.,  74.,  86., 251.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,   4.,   4.,  10.,\n",
      "           2.,   6.,   7.,  18.,  15.,  35., 105., 290.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  11.,   4.,   2.,  14.,\n",
      "           1.,   6.,   9.,  12.,  17.,  36., 112., 276.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,   8.,   5.,   9.,\n",
      "           2.,  11.,  10.,  28.,  25.,  45., 101., 254.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4.,   1.,  28.,  26.,\n",
      "           2.,   6.,   9.,  20.,  17.,  36., 120., 231.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   5.,   1.,   3.,   1.,   6.,  48.,\n",
      "           2.,   2.,   7.,  18.,  26.,  28.,  74., 279.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   1.,   2.,   1.,   3.,   3.,   1.,  14.,\n",
      "          24.,   5.,   9.,  19.,  19.,  39., 106., 254.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   5.,   9.,\n",
      "           1.,  33.,   7.,  23.,  24.,  44.,  93., 259.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,   2.,   3.,   0.,  12.,\n",
      "           5.,   6.,  50.,  19.,  24.,  27.,  77., 271.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   4.,   0.,   4.,  13.,\n",
      "           1.,   6.,  13., 123.,  19.,  33., 103., 180.],\n",
      "        [  0.,   0.,   0.,   2.,   0.,   1.,   2.,   0.,   1.,   4.,   0.,  11.,\n",
      "           1.,   5.,   6.,  26.,  97.,  34., 101., 209.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   4.,   1.,   2.,   5.,\n",
      "           1.,   6.,  10.,  17.,  19., 172.,  77., 183.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,   2.,   1.,   2.,  10.,\n",
      "           1.,   3.,   4.,  21.,  10.,  30., 277., 137.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,   3.,  23.,\n",
      "           0.,   1.,  10.,   9.,  15.,  27.,  53., 357.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming context_matrices is the total number of possible context matrices\n",
    "num_context_matrices = 20\n",
    "context_matrix_counts = torch.zeros(len(test_loaders), num_context_matrices)  # To store the count of each context matrix for every task\n",
    "\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "\n",
    "            # Expand batch_x to accommodate the number of context_matrices\n",
    "            batch_size = batch_x.size(0)\n",
    "            expanded_batch_x = batch_x.unsqueeze(1).repeat(1, num_context_matrices, 1, 1, 1)\n",
    "            \n",
    "            # Store logits for all context_matrices\n",
    "            all_logits = torch.zeros(batch_size, num_context_matrices, 100).cuda()\n",
    "            \n",
    "            # Compute logits for each context_matrix and store them\n",
    "            for context_idx in range(num_context_matrices):\n",
    "                logits, _, _ = model(expanded_batch_x[:, context_idx], context_idx)\n",
    "                all_logits[:, context_idx, :] = logits\n",
    "\n",
    "            # Find the maximum logit for each sample across all context_matrices\n",
    "            max_logits, best_context_indices = torch.max(all_logits.max(dim=-1)[0], dim=1)\n",
    "            \n",
    "            # Count the occurrences of the best context matrix\n",
    "            for idx in range(batch_size):\n",
    "                context_matrix_counts[task, best_context_indices[idx]] += 1\n",
    "\n",
    "# Print the context matrix count for each task\n",
    "print(context_matrix_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed2b5ee3-7ff0-419e-a55a-18785a02059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   1.,   1.,   2.,  16.,\n",
       "          4.,   7.,  10.,  25.,  22.,  22., 118., 271.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_matrix_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83883d75-841c-4f87-9712-562aab14ff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [500.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming context_matrices is the total number of possible context matrices\n",
    "num_context_matrices = 20\n",
    "temperature = 2.0  # You can adjust this for more or less smoothing\n",
    "context_matrix_counts = torch.zeros(len(test_loaders), num_context_matrices)  # To store the count of each context matrix for every task\n",
    "\n",
    "def smooth_and_project(logits, temp=10, range_min=0.0, range_max=1.0):\n",
    "    # Step 1: Apply temperature scaling to smooth the logits\n",
    "    smoothed_logits = F.softmax(logits / temp, dim=-1)  # Apply softmax with temperature scaling\n",
    "\n",
    "    # Step 2: Normalize the logits to the [range_min, range_max] range\n",
    "    min_val = smoothed_logits.min(dim=-1, keepdim=True)[0]  # Get the minimum value\n",
    "    max_val = smoothed_logits.max(dim=-1, keepdim=True)[0]  # Get the maximum value\n",
    "    projected_logits = (smoothed_logits - min_val) / (max_val - min_val)  # Min-max normalization\n",
    "    projected_logits = projected_logits * (range_max - range_min) + range_min  # Scale to the desired range\n",
    "\n",
    "    return projected_logits\n",
    "\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "\n",
    "            # Expand batch_x to accommodate the number of context_matrices\n",
    "            batch_size = batch_x.size(0)\n",
    "            expanded_batch_x = batch_x.unsqueeze(1).repeat(1, num_context_matrices, 1, 1, 1)\n",
    "            \n",
    "            # Store logits for all context_matrices\n",
    "            all_logits = torch.zeros(batch_size, num_context_matrices, 100).cuda()\n",
    "            \n",
    "            # Compute logits for each context_matrix and store them\n",
    "            for context_idx in range(num_context_matrices):\n",
    "                logits, _, _ = model(expanded_batch_x[:, context_idx], context_idx)\n",
    "                all_logits[:, context_idx, :] = logits\n",
    "\n",
    "            # Step 3: Smooth and project logits before proceeding\n",
    "            smoothed_logits = smooth_and_project(all_logits, temp=temperature)\n",
    "\n",
    "            # Step 4: Find the maximum smoothed logit for each sample across all context_matrices\n",
    "            max_logits, best_context_indices = torch.max(smoothed_logits.max(dim=-1)[0], dim=1)\n",
    "            \n",
    "            # Count the occurrences of the best context matrix\n",
    "            for idx in range(batch_size):\n",
    "                context_matrix_counts[task, best_context_indices[idx]] += 1\n",
    "\n",
    "# Print the context matrix count for each task\n",
    "print(context_matrix_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69984921-029a-4327-a67a-dda026a460cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.,  37.,  38.,  61., 350.],\n",
      "        [ 51.,  34.,  48.,  83., 284.],\n",
      "        [ 27.,  55.,  42.,  75., 301.],\n",
      "        [ 17.,  37.,  40.,  90., 316.],\n",
      "        [ 27.,  42.,  55.,  97., 279.],\n",
      "        [ 24.,  44.,  65.,  84., 283.],\n",
      "        [  6.,  19.,  27., 120., 328.],\n",
      "        [  8.,  26.,  35.,  91., 340.],\n",
      "        [ 10.,  29.,  41.,  59., 361.],\n",
      "        [  8.,  29.,  41.,  73., 349.],\n",
      "        [ 24.,  32.,  39.,  52., 353.],\n",
      "        [ 15.,  37.,  46.,  87., 315.],\n",
      "        [ 13.,  30.,  49.,  83., 325.],\n",
      "        [  4.,  19.,  28.,  83., 366.],\n",
      "        [ 10.,  24.,  25.,  89., 352.],\n",
      "        [ 16.,  43.,  44.,  77., 320.],\n",
      "        [  8.,  34.,  30.,  76., 352.],\n",
      "        [ 30.,  38.,  26.,  91., 315.],\n",
      "        [ 15.,  35.,  53.,  55., 342.],\n",
      "        [ 14.,  42.,  33.,  95., 316.]])\n"
     ]
    }
   ],
   "source": [
    "checkpoint2_path = f'./checkpoint/Superposition_batch500_task10_epoch1_mce_checkpoint_run0_batch5_epoch0.pth'\n",
    "checkpoint = torch.load(checkpoint2_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "num_context_matrices = 5\n",
    "context_matrix_counts = torch.zeros(len(test_loaders), num_context_matrices)  # To store the count of each context matrix for every task\n",
    "\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "\n",
    "            # Expand batch_x to accommodate the number of context_matrices\n",
    "            batch_size = batch_x.size(0)\n",
    "            expanded_batch_x = batch_x.unsqueeze(1).repeat(1, num_context_matrices, 1, 1, 1)\n",
    "            \n",
    "            # Store logits for all context_matrices\n",
    "            all_logits = torch.zeros(batch_size, num_context_matrices, 100).cuda()\n",
    "            \n",
    "            # Compute logits for each context_matrix and store them\n",
    "            for context_idx in range(num_context_matrices):\n",
    "                logits, _, _ = model(expanded_batch_x[:, context_idx], context_idx)\n",
    "                all_logits[:, context_idx, :] = logits\n",
    "\n",
    "            # Find the maximum logit for each sample across all context_matrices\n",
    "            max_logits, best_context_indices = torch.max(all_logits.max(dim=-1)[0], dim=1)\n",
    "            \n",
    "            # Count the occurrences of the best context matrix\n",
    "            for idx in range(batch_size):\n",
    "                context_matrix_counts[task, best_context_indices[idx]] += 1\n",
    "\n",
    "# Print the context matrix count for each task\n",
    "print(context_matrix_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5bfbb31-8524-4667-b8fc-e4eceabee590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 65.,  78.,  69.,  83., 205.],\n",
      "        [ 81.,  88.,  68., 115., 148.],\n",
      "        [ 25., 141.,  73.,  95., 166.],\n",
      "        [ 33., 117.,  48.,  91., 211.],\n",
      "        [ 22.,  42., 135., 142., 159.],\n",
      "        [ 21.,  54., 138.,  94., 193.],\n",
      "        [ 13.,  36.,  36., 252., 163.],\n",
      "        [ 15.,  50.,  43., 206., 186.],\n",
      "        [ 18.,  43.,  36.,  47., 356.],\n",
      "        [ 24.,  41.,  37.,  88., 310.],\n",
      "        [ 29.,  66.,  61., 114., 230.],\n",
      "        [ 26.,  66.,  53., 165., 190.],\n",
      "        [ 26.,  79.,  63., 123., 209.],\n",
      "        [ 21.,  66.,  55., 124., 234.],\n",
      "        [ 33.,  48.,  63., 153., 203.],\n",
      "        [ 34.,  96.,  61., 112., 197.],\n",
      "        [ 39.,  65.,  49., 129., 218.],\n",
      "        [ 31.,  97.,  66., 106., 200.],\n",
      "        [ 42.,  72.,  73., 109., 204.],\n",
      "        [ 42.,  70.,  67., 140., 181.]])\n"
     ]
    }
   ],
   "source": [
    "checkpoint2_path = f'./checkpoint/Superposition_batch500_task10_epoch50_smooth_checkpoint_run0_batch5_epoch49.pth'\n",
    "checkpoint = torch.load(checkpoint2_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "num_context_matrices = 10\n",
    "context_matrix_counts = torch.zeros(len(test_loaders), num_context_matrices)  # To store the count of each context matrix for every task\n",
    "\n",
    "with torch.no_grad():\n",
    "    for task, test_loader in enumerate(test_loaders):\n",
    "        for i, (batch_x, batch_y) in enumerate(test_loader):\n",
    "            batch_x = maybe_cuda(batch_x, \"cuda\")\n",
    "            batch_y = maybe_cuda(batch_y, \"cuda\")\n",
    "\n",
    "            # Expand batch_x to accommodate the number of context_matrices\n",
    "            batch_size = batch_x.size(0)\n",
    "            expanded_batch_x = batch_x.unsqueeze(1).repeat(1, num_context_matrices, 1, 1, 1)\n",
    "            \n",
    "            # Store logits for all context_matrices\n",
    "            all_logits = torch.zeros(batch_size, num_context_matrices, 100).cuda()\n",
    "            \n",
    "            # Compute logits for each context_matrix and store them\n",
    "            for context_idx in range(num_context_matrices):\n",
    "                logits, _, _ = model(expanded_batch_x[:, context_idx], context_idx)\n",
    "                all_logits[:, context_idx, :] = logits\n",
    "\n",
    "            # Find the maximum logit for each sample across all context_matrices\n",
    "            max_logits, best_context_indices = torch.max(all_logits.max(dim=-1)[0], dim=1)\n",
    "            \n",
    "            # Count the occurrences of the best context matrix\n",
    "            for idx in range(batch_size):\n",
    "                context_matrix_counts[task, best_context_indices[idx]] += 1\n",
    "\n",
    "# Print the context matrix count for each task\n",
    "print(context_matrix_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f45622-e4e7-4ee7-bcae-725e2f89313a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
